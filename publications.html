<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>zsz1997 </title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">MENU</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="publications.html">Publications</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Shengzhou Zhong </h1>
</div>
<h3>2021</h3>
<ul>
<li><p style="width:1500px">
<img src="pic/Fig2.png" align="left" width="300" hspace="10" vspace="10">
<div style="color:blue">[IEEE TMI]</div>Zhenyuan Ning, Shengzhou Zhong, Qianjin Feng, Wufan Chen, and<b>Yu Zhang</b>.SMU-Net: Saliency-guided Morphology-aware U-Net for Breast Lesion Segmentation in Ultrasound Image. <a href="https://ieeexplore.ieee.org/abstract/document/9551285">https://ieeexplore.ieee.org/abstract/document/9551285.</a>
<br/>Deep learning methods, especially convolutional neural networks, have been successfully applied to lesion segmentation in breast ultrasound (BUS) images. However, pattern complexity and intensity similarity between the surrounding tissues (i.e., background) and lesion regions (i.e., foreground) bring challenges for lesion segmentation. Considering that such rich texture information is contained in background, very few methods have tried to explore and exploit background-salient representations for assisting foreground segmentation. Additionally, other characteristics of BUS images, i.e., 1) low-contrast appearance and blurry boundary, and 2) significant shape and position variation of lesions, also increase the difficulty in accurate lesion segmentation. In this paper, we present a saliency-guided morphology-aware U-Net (SMU-Net) for lesion segmentation in BUS images. The SMU-Net is composed of a main network with an additional middle stream and an auxiliary network. Specifically, we first propose generation of saliency maps which incorporate both low-level and high-level image structures, for foreground and background. These saliency maps are then employed to guide the main network and auxiliary network for respectively learning foreground-salient and background-salient representations. Furthermore, we devise an additional middle stream which basically consists of background-assisted fusion, shape-aware, edge-aware and position-aware units. This stream receives the coarse-to-fine representations from the main network and auxiliary network for efficiently fusing the foreground-salient and background-salient features and enhancing the ability of learning morphological information for network. Extensive experiments on five datasets demonstrate higher performance and superior robustness to the scale of dataset than several state-of-the-art deep learning approaches in breast lesion segmentation in ultrasound image.
</p>
</li>
</ul>
<h3>2020 </h3>
<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/9272749">Viral Pneumonia Screening on Chest X-rays Using Confidence-Aware Anomaly Detection</a> <br />
<b>Jianpeng Zhang</b>*, Yutong Xie*, Guansong Pang, Zhibin Liao, Johan Verjans, Wenxing Li, Zongji Sun, Jian He, Yi Li, Chunhua Shen, Yong Xia (* Equal contribution) <br />
<i>IEEE Transactions on Medical Imaging (TMI)</i>, vol. 40, no. 3, pp. 879-890. <br />
<a href="https://arxiv.org/pdf/2003.12338.pdf">[arXiv]</a></p>
</li>
</ul>
<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/9245569">Inter-slice Context Residual Learning for 3D Medical Image Segmentation</a> <br />
<b>Jianpeng Zhang</b>, Yutong Xie, Yan Wang, and Yong Xia <br />
<i>IEEE Transactions on Medical Imaging (TMI)</i>, vol. 40, no. 2, pp. 661-672. <br />
<a href="https://arxiv.org/pdf/2011.14155.pdf">[arXiv]</a> <a href="https://github.com/jianpengz/ConResNet">[Code]</a></p>
</li>
</ul>
<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/9201384">SESV: Accurate Medical Image Segmentation by Predicting and Correcting Errors</a> <br />
Yutong Xie*, <b>Jianpeng Zhang</b>*, Hao Lu, Chunhua Shen, and Yong Xia (* Equal contribution) <br />
<i>IEEE Transactions on Medical Imaging (TMI)</i>, vol. 40, no. 1, pp. 286-296.</p>
</li>
</ul>
<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/8990108">A Mutual Bootstrapping Model for Automated Skin Lesion Segmentation and Classification</a> <br />
Yutong Xie*, <b>Jianpeng Zhang</b>*, Yong Xia and Chunhua Shen (* Equal contribution) <br />
<i>IEEE Transactions on Medical Imaging (TMI)</i>, vol. 39, no. 7, pp. 2482-2493. <br />
<a href="https://arxiv.org/pdf/1903.03313.pdf">[arXiv]</a> <a href="https://github.com/YtongXie/MB-DCNN">[Code]</a></p>
</li>
</ul>
<ul>
<li><p><a href="https://link.springer.com/chapter/10.1007%2F978-3-030-59722-1_40">Pairwise Relation Learning for Semi-supervised Gland Segmentation</a> <br />
Yutong Xie, <b>Jianpeng Zhang</b>, Zhibin Liao, Chunhua Shen, Johan Verjans and Yong Xia <br />
<i>International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI 2020)</i>. <br />
<a href="https://arxiv.org/pdf/2008.02699.pdf">[arXiv]</a></p>
</li>
</ul>
<ul>
<li><p><a href="https://link.springer.com/chapter/10.1007/978-3-030-65651-5_2">EfficientSeg: A Simple But Efficient Solution to Myocardial Pathology Segmentation Challenge</a> <br />
<b>Jianpeng Zhang</b>, Yutong Xie, Zhibin Liao, Johan Verjans and Yong Xia <br />
<i>Myocardial Pathology Segmentation Combining Multi-Sequence Cardiac Magnetic Resonance Images (MyoPS 2020)</i>. <br />
<a href="https://github.com/jianpengz/EfficientSeg">[Code]</a></p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2011.12640.pdf">PGL: Prior-Guided Local Self-supervised Learning for 3D Medical Image Segmentation</a> <br />
Yutong Xie*, <b>Jianpeng Zhang</b>*, Zehui Liao, Yong Xia, and Chunhua Shen (* Equal contribution) <br />
<i>arXiv:2011.12640</i>. <br />
<a href="https://arxiv.org/pdf/2011.12640.pdf">[arXiv]</a></p>
</li>
</ul>
<h3>2019</h3>
<ul>
<li><p><a href="https://ieeexplore.ieee.org/abstract/document/8620285">Attention residual learning for skin lesion classification</a> <br />
<b>Jianpeng Zhang</b>, Yutong Xie, Yong Xia, Chunhua Shen <br />
<i>IEEE Transactions on Medical Imaging (TMI)</i>, vol. 38, no. 9, pp. 2092-2103. <font color="red">(ESI Highly Cited Paper) </font></p>
</li>
</ul>
<ul>
<li><p><a href="https://www.sciencedirect.com/science/article/pii/S1361841518307552">Medical image classification using synergic deep learning</a> <br />
<b>Jianpeng Zhang</b>, Yutong Xie, Qi Wu, Yong Xia <br />
<i>Medical Image Analysis (MedIA)</i>, vol. 54, pp. 10-19. </p>
</li>
</ul>
<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/8494708">Knowledge-based Collaborative Deep Learning for Benign-Malignant Lung Nodule Classification on Chest CT</a> <br />
Yutong Xie, Yong Xia, <b>Jianpeng Zhang</b>, Yang Song, David Dagan Feng, Michael Fulham, Weidong Cai <br />
<i>IEEE Transactions on Medical Imaging (TMI)</i>, vol. 38, issue 4, pp. 991-1004. <font color="red">(ESI Highly Cited Paper) </font> <br /> 
<a href="https://github.com/YtongXie/MVKBC-model-for-lung-nodule-classification">[Code]</a></p>
</li>
</ul>
<ul>
<li><p><a href="https://www.sciencedirect.com/science/article/pii/S1361841519300611">Semi-supervised adversarial model for benign&ndash;malignant lung nodule classification on chest CT</a> <br />
Yutong Xie, <b>Jianpeng Zhang</b>, Yong Xia <br />
<i>Medical Image Analysis (MedIA)</i>, vol. 57, pp. 237-248. </p>
</li>
</ul>
<ul>
<li><p><a href="https://www.ijcai.org/Proceedings/2019/0593.pdf">Light-Weight Hybrid Convolutional Network for Liver Tumor Segmentation</a> <br />
<b>Jianpeng Zhang</b>, Yutong Xie, Pingping Zhang, Hao Chen, Yong Xia, Chunhua Shen <br />
<i>International Joint Conferences on Artificial Intelligence (IJCAI 2019)</i>. </p>
</li>
</ul>
<ul>
<li><p><a href="https://link.springer.com/chapter/10.1007/978-3-030-32239-7_52">Deep Segmentation-Emendation Model for Gland Instance Segmentation</a> <br />
Yutong Xie, Hao Lu, <b>Jianpeng Zhang</b>, Chunhua Shen, Yong Xia <br />
<i>International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI 2019)</i>. </p>
</li>
</ul>
<h3>2018</h3>
<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/8115141">Classification of medical images in biomedical literature by jointly using deep and handcrafted visual features</a> <br />
<b>Jianpeng Zhang</b>, Yong Xia, Yutong Xie, Michael Fulham, David Dagan Feng <br />
<i>IEEE Journal of Biomedical and Health Informatics (JBHI)</i>, vol. 22, no. 5, pp. 1521-1530. <br /></p>
</li>
</ul>
<ul>
<li><p><a href="https://link.springer.com/chapter/10.1007/978-3-030-00934-2_2">Skin lesion classification in dermoscopy images using synergic deep learning</a> <br />
<b>Jianpeng Zhang</b>, Yutong Xie, Qi Wu, Yong Xia <br />
<i>International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI 2018)</i>. </p>
</li>
</ul>
<ul>
<li><p><a href="https://www.sciencedirect.com/science/article/pii/S1566253516301063">Fusing texture, shape and deep model-learned information at decision level for automated classification of lung nodules on chest CT</a> <br />
Yutong Xie, <b>Jianpeng Zhang</b>, Yong Xia, Michael Fulham, and Yanning Zhang <br />
<i>Information Fusion</i>, vol. 42, pp. 102-110. <font color="red">(ESI Highly Cited Paper) </font></p>
</li>
</ul>
<h3>2017</h3>
<ul>
<li><p><a href="https://link.springer.com/chapter/10.1007/978-3-319-66179-7_75">Transferable Multi-model Ensemble for Benign-Malignant Lung Nodule Classification on Chest CT</a> <br />
Yutong Xie, Yong Xia, <b>Jianpeng Zhang</b>, David Dagan Feng, Michael Fulham and Weidong Cai <br />
<i>International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI 2017)</i>.</p>
</li>
</ul>
</td>
</tr>
</table>
</body>
</html>
