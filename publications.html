<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>zsz1997 </title>
<style>
    .word{background:#E4FFE9;width:250px;margin:50px auto;padding:20px;font-family:"microsoft yahei";}
    /* 强制不换行 */
    .nowrap{white-space:nowrap;}
    /* 允许单词内断句，首先会尝试挪到下一行，看看下一行的宽度够不够，
    不够的话就进行单词内的断句 */
    .breakword{word-wrap: break-word;}
    /* 断句时，不会把长单词挪到下一行，而是直接进行单词内的断句 */
    .breakAll{word-break:break-all;}            
    /* 超出部分显示省略号 */
    .ellipsis{text-overflow:ellipsis;overflow:hidden;}
    .divcss5 span{ font-size:20px}
    .auto_align{text-align:justify;-webkit-hyphens:auto;-moz-hyphens:auto;-ms-hyphens:auto;hyphens:auto;}
</style>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">MENU</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="publications.html">Publications</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Shengzhou Zhong </h1>
</div>
<h3>2021</h3>
  
<ul>
<p style="width:1400px" class="auto_align">
  <span>1</span>. Zhenyuan Ning, Shengzhou Zhong, Qianjin Feng, Wufan Chen, and <b>Yu Zhang</b>.
  SMU-Net: Saliency-guided Morphology-aware U-Net for Breast Lesion Segmentation in Ultrasound Image. 
  <i style="color:#3333CC">IEEE Transactions on Medical Imaging (TMI).</i>
  <a href="https://ieeexplore.ieee.org/abstract/document/9551285">[PDF]</a>
  <a href="https://github.com/YuZhang-SMU/Breast-Lesion-Segmentation">[Code]</a>
</p>
<p style="width:1400px" class="auto_align">
  <img src="pic/Fig2.png" align="left" width="500" hspace="5" vspace="5">
  <p style="width:1400px" class="divcss5 auto_align">
  <b>
  <span>
  [Abstract]
  </span>
  </b>
  Deep learning methods, especially convolutional neural networks, have been successfully applied to lesion segmentation in breast ultrasound (BUS) images. However, pattern complexity and intensity similarity between the surrounding tissues (i.e., background) and lesion regions (i.e., foreground) bring challenges for lesion segmentation. Considering that such rich texture information is contained in background, very few methods have tried to explore and exploit background-salient representations for assisting foreground segmentation. Additionally, other characteristics of BUS images, i.e., 1) low-contrast appearance and blurry boundary, and 2) significant shape and position variation of lesions, also increase the difficulty in accurate lesion segmentation. In this paper, we present a saliency-guided morphology-aware U-Net (SMU-Net) for lesion segmentation in BUS images. The SMU-Net is composed of a main network with an additional middle stream and an auxiliary network. Specifically, we first propose generation of saliency maps which incorporate both low-level and high-level image structures, for foreground and background. These saliency maps are then employed to guide the main network and auxiliary network for respectively learning foreground-salient and background-salient representations. Furthermore, we devise an additional middle stream which basically consists of background-assisted fusion, shape-aware, edge-aware and position-aware units. This stream receives the coarse-to-fine representations from the main network and auxiliary network for efficiently fusing the foreground-salient and background-salient features and enhancing the ability of learning morphological information for network. Extensive experiments on five datasets demonstrate higher performance and superior robustness to the scale of dataset than several state-of-the-art deep learning approaches in breast lesion segmentation in ultrasound image.
  </p>
</p>
</ul>
 
 <ul>
<p style="width:1400px" class="auto_align">
  <span>2</span>. Zhenyuan Ning, Shengzhou Zhong, Qianjin Feng, Wufan Chen, and <b>Yu Zhang</b>.
  SMU-Net: Saliency-guided Morphology-aware U-Net for Breast Lesion Segmentation in Ultrasound Image. 
  <i style="color:#3333CC">IEEE Transactions on Medical Imaging (TMI).</i>
  <a href="https://ieeexplore.ieee.org/abstract/document/9551285">[PDF]</a>
  <a href="https://github.com/YuZhang-SMU/Breast-Lesion-Segmentation">[Code]</a>
</p>
<p style="width:1400px" class="auto_align">
  <img src="pic/Fig2.png" align="left" width="500" hspace="5" vspace="5">
  <p style="width:1400px" class="divcss5 auto_align">
  <b>
  <span>
  [Abstract]
  </span>
  </b>
  Deep learning methods, especially convolutional neural networks, have been successfully applied to lesion segmentation in breast ultrasound (BUS) images. However, pattern complexity and intensity similarity between the surrounding tissues (i.e., background) and lesion regions (i.e., foreground) bring challenges for lesion segmentation. Considering that such rich texture information is contained in background, very few methods have tried to explore and exploit background-salient representations for assisting foreground segmentation. Additionally, other characteristics of BUS images, i.e., 1) low-contrast appearance and blurry boundary, and 2) significant shape and position variation of lesions, also increase the difficulty in accurate lesion segmentation. In this paper, we present a saliency-guided morphology-aware U-Net (SMU-Net) for lesion segmentation in BUS images. The SMU-Net is composed of a main network with an additional middle stream and an auxiliary network. Specifically, we first propose generation of saliency maps which incorporate both low-level and high-level image structures, for foreground and background. These saliency maps are then employed to guide the main network and auxiliary network for respectively learning foreground-salient and background-salient representations. Furthermore, we devise an additional middle stream which basically consists of background-assisted fusion, shape-aware, edge-aware and position-aware units. This stream receives the coarse-to-fine representations from the main network and auxiliary network for efficiently fusing the foreground-salient and background-salient features and enhancing the ability of learning morphological information for network. Extensive experiments on five datasets demonstrate higher performance and superior robustness to the scale of dataset than several state-of-the-art deep learning approaches in breast lesion segmentation in ultrasound image.
  </p>
</p>
</ul>
 
<ul>
<p style="width:1400px" class="auto_align">
  <span>3</span>. Zhenyuan Ning, Shengzhou Zhong, Qianjin Feng, Wufan Chen, and <b>Yu Zhang</b>.
  SMU-Net: Saliency-guided Morphology-aware U-Net for Breast Lesion Segmentation in Ultrasound Image. 
  <i style="color:#3333CC">IEEE Transactions on Medical Imaging (TMI).</i>
  <a href="https://ieeexplore.ieee.org/abstract/document/9551285">[PDF]</a>
  <a href="https://github.com/YuZhang-SMU/Breast-Lesion-Segmentation">[Code]</a>
</p>
<p style="width:1400px" class="auto_align">
  <img src="pic/Fig2.png" align="left" width="500" hspace="5" vspace="5">
  <p style="width:1400px" class="divcss5 auto_align">
  <b>
  <span>
  [Abstract]
  </span>
  </b>
  Deep learning methods, especially convolutional neural networks, have been successfully applied to lesion segmentation in breast ultrasound (BUS) images. However, pattern complexity and intensity similarity between the surrounding tissues (i.e., background) and lesion regions (i.e., foreground) bring challenges for lesion segmentation. Considering that such rich texture information is contained in background, very few methods have tried to explore and exploit background-salient representations for assisting foreground segmentation. Additionally, other characteristics of BUS images, i.e., 1) low-contrast appearance and blurry boundary, and 2) significant shape and position variation of lesions, also increase the difficulty in accurate lesion segmentation. In this paper, we present a saliency-guided morphology-aware U-Net (SMU-Net) for lesion segmentation in BUS images. The SMU-Net is composed of a main network with an additional middle stream and an auxiliary network. Specifically, we first propose generation of saliency maps which incorporate both low-level and high-level image structures, for foreground and background. These saliency maps are then employed to guide the main network and auxiliary network for respectively learning foreground-salient and background-salient representations. Furthermore, we devise an additional middle stream which basically consists of background-assisted fusion, shape-aware, edge-aware and position-aware units. This stream receives the coarse-to-fine representations from the main network and auxiliary network for efficiently fusing the foreground-salient and background-salient features and enhancing the ability of learning morphological information for network. Extensive experiments on five datasets demonstrate higher performance and superior robustness to the scale of dataset than several state-of-the-art deep learning approaches in breast lesion segmentation in ultrasound image.
  </p>
</p>
</ul>

<ul>
<p style="width:1400px" class="auto_align">
  <span>4</span>. Zhenyuan Ning, Shengzhou Zhong, Qianjin Feng, Wufan Chen, and <b>Yu Zhang</b>.
  SMU-Net: Saliency-guided Morphology-aware U-Net for Breast Lesion Segmentation in Ultrasound Image. 
  <i style="color:#3333CC">IEEE Transactions on Medical Imaging (TMI).</i>
  <a href="https://ieeexplore.ieee.org/abstract/document/9551285">[PDF]</a>
  <a href="https://github.com/YuZhang-SMU/Breast-Lesion-Segmentation">[Code]</a>
</p>
<p style="width:1400px" class="auto_align">
  <img src="pic/Fig2.png" align="left" width="500" hspace="5" vspace="5">
  <p style="width:1400px" class="divcss5 auto_align">
  <b>
  <span>
  [Abstract]
  </span>
  </b>
  Deep learning methods, especially convolutional neural networks, have been successfully applied to lesion segmentation in breast ultrasound (BUS) images. However, pattern complexity and intensity similarity between the surrounding tissues (i.e., background) and lesion regions (i.e., foreground) bring challenges for lesion segmentation. Considering that such rich texture information is contained in background, very few methods have tried to explore and exploit background-salient representations for assisting foreground segmentation. Additionally, other characteristics of BUS images, i.e., 1) low-contrast appearance and blurry boundary, and 2) significant shape and position variation of lesions, also increase the difficulty in accurate lesion segmentation. In this paper, we present a saliency-guided morphology-aware U-Net (SMU-Net) for lesion segmentation in BUS images. The SMU-Net is composed of a main network with an additional middle stream and an auxiliary network. Specifically, we first propose generation of saliency maps which incorporate both low-level and high-level image structures, for foreground and background. These saliency maps are then employed to guide the main network and auxiliary network for respectively learning foreground-salient and background-salient representations. Furthermore, we devise an additional middle stream which basically consists of background-assisted fusion, shape-aware, edge-aware and position-aware units. This stream receives the coarse-to-fine representations from the main network and auxiliary network for efficiently fusing the foreground-salient and background-salient features and enhancing the ability of learning morphological information for network. Extensive experiments on five datasets demonstrate higher performance and superior robustness to the scale of dataset than several state-of-the-art deep learning approaches in breast lesion segmentation in ultrasound image.
  </p>
</p>
</ul>
 
<ul>
<p style="width:1400px" class="auto_align">
  <span>5</span>. Zhenyuan Ning, Shengzhou Zhong, Qianjin Feng, Wufan Chen, and <b>Yu Zhang</b>.
  SMU-Net: Saliency-guided Morphology-aware U-Net for Breast Lesion Segmentation in Ultrasound Image. 
  <i style="color:#3333CC">IEEE Transactions on Medical Imaging (TMI).</i>
  <a href="https://ieeexplore.ieee.org/abstract/document/9551285">[PDF]</a>
  <a href="https://github.com/YuZhang-SMU/Breast-Lesion-Segmentation">[Code]</a>
</p>
<p style="width:1400px" class="auto_align">
  <img src="pic/Fig2.png" align="left" width="500" hspace="5" vspace="5">
  <p style="width:1400px" class="divcss5 auto_align">
  <b>
  <span>
  [Abstract]
  </span>
  </b>
  Deep learning methods, especially convolutional neural networks, have been successfully applied to lesion segmentation in breast ultrasound (BUS) images. However, pattern complexity and intensity similarity between the surrounding tissues (i.e., background) and lesion regions (i.e., foreground) bring challenges for lesion segmentation. Considering that such rich texture information is contained in background, very few methods have tried to explore and exploit background-salient representations for assisting foreground segmentation. Additionally, other characteristics of BUS images, i.e., 1) low-contrast appearance and blurry boundary, and 2) significant shape and position variation of lesions, also increase the difficulty in accurate lesion segmentation. In this paper, we present a saliency-guided morphology-aware U-Net (SMU-Net) for lesion segmentation in BUS images. The SMU-Net is composed of a main network with an additional middle stream and an auxiliary network. Specifically, we first propose generation of saliency maps which incorporate both low-level and high-level image structures, for foreground and background. These saliency maps are then employed to guide the main network and auxiliary network for respectively learning foreground-salient and background-salient representations. Furthermore, we devise an additional middle stream which basically consists of background-assisted fusion, shape-aware, edge-aware and position-aware units. This stream receives the coarse-to-fine representations from the main network and auxiliary network for efficiently fusing the foreground-salient and background-salient features and enhancing the ability of learning morphological information for network. Extensive experiments on five datasets demonstrate higher performance and superior robustness to the scale of dataset than several state-of-the-art deep learning approaches in breast lesion segmentation in ultrasound image.
  </p>
</p>
</ul>

<ul>
<p style="width:1400px" class="auto_align">
  <span>6</span>. Zhenyuan Ning, Shengzhou Zhong, Qianjin Feng, Wufan Chen, and <b>Yu Zhang</b>.
  SMU-Net: Saliency-guided Morphology-aware U-Net for Breast Lesion Segmentation in Ultrasound Image. 
  <i style="color:#3333CC">IEEE Transactions on Medical Imaging (TMI).</i>
  <a href="https://ieeexplore.ieee.org/abstract/document/9551285">[PDF]</a>
  <a href="https://github.com/YuZhang-SMU/Breast-Lesion-Segmentation">[Code]</a>
</p>
<p style="width:1400px" class="auto_align">
  <img src="pic/Fig2.png" align="left" width="500" hspace="5" vspace="5">
  <p style="width:1400px" class="divcss5 auto_align">
  <b>
  <span>
  [Abstract]
  </span>
  </b>
  Deep learning methods, especially convolutional neural networks, have been successfully applied to lesion segmentation in breast ultrasound (BUS) images. However, pattern complexity and intensity similarity between the surrounding tissues (i.e., background) and lesion regions (i.e., foreground) bring challenges for lesion segmentation. Considering that such rich texture information is contained in background, very few methods have tried to explore and exploit background-salient representations for assisting foreground segmentation. Additionally, other characteristics of BUS images, i.e., 1) low-contrast appearance and blurry boundary, and 2) significant shape and position variation of lesions, also increase the difficulty in accurate lesion segmentation. In this paper, we present a saliency-guided morphology-aware U-Net (SMU-Net) for lesion segmentation in BUS images. The SMU-Net is composed of a main network with an additional middle stream and an auxiliary network. Specifically, we first propose generation of saliency maps which incorporate both low-level and high-level image structures, for foreground and background. These saliency maps are then employed to guide the main network and auxiliary network for respectively learning foreground-salient and background-salient representations. Furthermore, we devise an additional middle stream which basically consists of background-assisted fusion, shape-aware, edge-aware and position-aware units. This stream receives the coarse-to-fine representations from the main network and auxiliary network for efficiently fusing the foreground-salient and background-salient features and enhancing the ability of learning morphological information for network. Extensive experiments on five datasets demonstrate higher performance and superior robustness to the scale of dataset than several state-of-the-art deep learning approaches in breast lesion segmentation in ultrasound image.
  </p>
</p>
</ul>

<h3>2020 </h3>
  
<ul>
<p style="width:1400px" class="auto_align">
  <span>1</span>. Zhenyuan Ning, Shengzhou Zhong, Qianjin Feng, Wufan Chen, and <b>Yu Zhang</b>.
  SMU-Net: Saliency-guided Morphology-aware U-Net for Breast Lesion Segmentation in Ultrasound Image. 
  <i style="color:#3333CC">IEEE Transactions on Medical Imaging (TMI).</i>
  <a href="https://ieeexplore.ieee.org/abstract/document/9551285">[PDF]</a>
  <a href="https://github.com/YuZhang-SMU/Breast-Lesion-Segmentation">[Code]</a>
</p>
<p style="width:1400px" class="auto_align">
  <img src="pic/Fig2.png" align="left" width="500" hspace="5" vspace="5">
  <p style="width:1400px" class="divcss5 auto_align">
  <b>
  <span>
  [Abstract]
  </span>
  </b>
  Deep learning methods, especially convolutional neural networks, have been successfully applied to lesion segmentation in breast ultrasound (BUS) images. However, pattern complexity and intensity similarity between the surrounding tissues (i.e., background) and lesion regions (i.e., foreground) bring challenges for lesion segmentation. Considering that such rich texture information is contained in background, very few methods have tried to explore and exploit background-salient representations for assisting foreground segmentation. Additionally, other characteristics of BUS images, i.e., 1) low-contrast appearance and blurry boundary, and 2) significant shape and position variation of lesions, also increase the difficulty in accurate lesion segmentation. In this paper, we present a saliency-guided morphology-aware U-Net (SMU-Net) for lesion segmentation in BUS images. The SMU-Net is composed of a main network with an additional middle stream and an auxiliary network. Specifically, we first propose generation of saliency maps which incorporate both low-level and high-level image structures, for foreground and background. These saliency maps are then employed to guide the main network and auxiliary network for respectively learning foreground-salient and background-salient representations. Furthermore, we devise an additional middle stream which basically consists of background-assisted fusion, shape-aware, edge-aware and position-aware units. This stream receives the coarse-to-fine representations from the main network and auxiliary network for efficiently fusing the foreground-salient and background-salient features and enhancing the ability of learning morphological information for network. Extensive experiments on five datasets demonstrate higher performance and superior robustness to the scale of dataset than several state-of-the-art deep learning approaches in breast lesion segmentation in ultrasound image.
  </p>
</p>
</ul>
  
<ul>
<p style="width:1400px" class="auto_align">
  <span>2</span>. Zhenyuan Ning, Shengzhou Zhong, Qianjin Feng, Wufan Chen, and <b>Yu Zhang</b>.
  SMU-Net: Saliency-guided Morphology-aware U-Net for Breast Lesion Segmentation in Ultrasound Image. 
  <i style="color:#3333CC">IEEE Transactions on Medical Imaging (TMI).</i>
  <a href="https://ieeexplore.ieee.org/abstract/document/9551285">[PDF]</a>
  <a href="https://github.com/YuZhang-SMU/Breast-Lesion-Segmentation">[Code]</a>
</p>
<p style="width:1400px" class="auto_align">
  <img src="pic/Fig2.png" align="left" width="500" hspace="5" vspace="5">
  <p style="width:1400px" class="divcss5 auto_align">
  <b>
  <span>
  [Abstract]
  </span>
  </b>
  Deep learning methods, especially convolutional neural networks, have been successfully applied to lesion segmentation in breast ultrasound (BUS) images. However, pattern complexity and intensity similarity between the surrounding tissues (i.e., background) and lesion regions (i.e., foreground) bring challenges for lesion segmentation. Considering that such rich texture information is contained in background, very few methods have tried to explore and exploit background-salient representations for assisting foreground segmentation. Additionally, other characteristics of BUS images, i.e., 1) low-contrast appearance and blurry boundary, and 2) significant shape and position variation of lesions, also increase the difficulty in accurate lesion segmentation. In this paper, we present a saliency-guided morphology-aware U-Net (SMU-Net) for lesion segmentation in BUS images. The SMU-Net is composed of a main network with an additional middle stream and an auxiliary network. Specifically, we first propose generation of saliency maps which incorporate both low-level and high-level image structures, for foreground and background. These saliency maps are then employed to guide the main network and auxiliary network for respectively learning foreground-salient and background-salient representations. Furthermore, we devise an additional middle stream which basically consists of background-assisted fusion, shape-aware, edge-aware and position-aware units. This stream receives the coarse-to-fine representations from the main network and auxiliary network for efficiently fusing the foreground-salient and background-salient features and enhancing the ability of learning morphological information for network. Extensive experiments on five datasets demonstrate higher performance and superior robustness to the scale of dataset than several state-of-the-art deep learning approaches in breast lesion segmentation in ultrasound image.
  </p>
</p>
</ul>
  
<ul>
<p style="width:1400px" class="auto_align">
  <span>3</span>. Zhenyuan Ning, Shengzhou Zhong, Qianjin Feng, Wufan Chen, and <b>Yu Zhang</b>.
  SMU-Net: Saliency-guided Morphology-aware U-Net for Breast Lesion Segmentation in Ultrasound Image. 
  <i style="color:#3333CC">IEEE Transactions on Medical Imaging (TMI).</i>
  <a href="https://ieeexplore.ieee.org/abstract/document/9551285">[PDF]</a>
  <a href="https://github.com/YuZhang-SMU/Breast-Lesion-Segmentation">[Code]</a>
</p>
<p style="width:1400px" class="auto_align">
  <img src="pic/Fig2.png" align="left" width="500" hspace="5" vspace="5">
  <p style="width:1400px" class="divcss5 auto_align">
  <b>
  <span>
  [Abstract]
  </span>
  </b>
  Deep learning methods, especially convolutional neural networks, have been successfully applied to lesion segmentation in breast ultrasound (BUS) images. However, pattern complexity and intensity similarity between the surrounding tissues (i.e., background) and lesion regions (i.e., foreground) bring challenges for lesion segmentation. Considering that such rich texture information is contained in background, very few methods have tried to explore and exploit background-salient representations for assisting foreground segmentation. Additionally, other characteristics of BUS images, i.e., 1) low-contrast appearance and blurry boundary, and 2) significant shape and position variation of lesions, also increase the difficulty in accurate lesion segmentation. In this paper, we present a saliency-guided morphology-aware U-Net (SMU-Net) for lesion segmentation in BUS images. The SMU-Net is composed of a main network with an additional middle stream and an auxiliary network. Specifically, we first propose generation of saliency maps which incorporate both low-level and high-level image structures, for foreground and background. These saliency maps are then employed to guide the main network and auxiliary network for respectively learning foreground-salient and background-salient representations. Furthermore, we devise an additional middle stream which basically consists of background-assisted fusion, shape-aware, edge-aware and position-aware units. This stream receives the coarse-to-fine representations from the main network and auxiliary network for efficiently fusing the foreground-salient and background-salient features and enhancing the ability of learning morphological information for network. Extensive experiments on five datasets demonstrate higher performance and superior robustness to the scale of dataset than several state-of-the-art deep learning approaches in breast lesion segmentation in ultrasound image.
  </p>
</p>
</ul>

<ul>
<p style="width:1400px" class="auto_align">
  <span>4</span>. Zhenyuan Ning, Shengzhou Zhong, Qianjin Feng, Wufan Chen, and <b>Yu Zhang</b>.
  SMU-Net: Saliency-guided Morphology-aware U-Net for Breast Lesion Segmentation in Ultrasound Image. 
  <i style="color:#3333CC">IEEE Transactions on Medical Imaging (TMI).</i>
  <a href="https://ieeexplore.ieee.org/abstract/document/9551285">[PDF]</a>
  <a href="https://github.com/YuZhang-SMU/Breast-Lesion-Segmentation">[Code]</a>
</p>
<p style="width:1400px" class="auto_align">
  <img src="pic/Fig2.png" align="left" width="500" hspace="5" vspace="5">
  <p style="width:1400px" class="divcss5 auto_align">
  <b>
  <span>
  [Abstract]
  </span>
  </b>
  Deep learning methods, especially convolutional neural networks, have been successfully applied to lesion segmentation in breast ultrasound (BUS) images. However, pattern complexity and intensity similarity between the surrounding tissues (i.e., background) and lesion regions (i.e., foreground) bring challenges for lesion segmentation. Considering that such rich texture information is contained in background, very few methods have tried to explore and exploit background-salient representations for assisting foreground segmentation. Additionally, other characteristics of BUS images, i.e., 1) low-contrast appearance and blurry boundary, and 2) significant shape and position variation of lesions, also increase the difficulty in accurate lesion segmentation. In this paper, we present a saliency-guided morphology-aware U-Net (SMU-Net) for lesion segmentation in BUS images. The SMU-Net is composed of a main network with an additional middle stream and an auxiliary network. Specifically, we first propose generation of saliency maps which incorporate both low-level and high-level image structures, for foreground and background. These saliency maps are then employed to guide the main network and auxiliary network for respectively learning foreground-salient and background-salient representations. Furthermore, we devise an additional middle stream which basically consists of background-assisted fusion, shape-aware, edge-aware and position-aware units. This stream receives the coarse-to-fine representations from the main network and auxiliary network for efficiently fusing the foreground-salient and background-salient features and enhancing the ability of learning morphological information for network. Extensive experiments on five datasets demonstrate higher performance and superior robustness to the scale of dataset than several state-of-the-art deep learning approaches in breast lesion segmentation in ultrasound image.
  </p>
</p>
</ul>

<ul>
<p style="width:1400px" class="auto_align">
  <span>5</span>. Zhenyuan Ning, Shengzhou Zhong, Qianjin Feng, Wufan Chen, and <b>Yu Zhang</b>.
  SMU-Net: Saliency-guided Morphology-aware U-Net for Breast Lesion Segmentation in Ultrasound Image. 
  <i style="color:#3333CC">IEEE Transactions on Medical Imaging (TMI).</i>
  <a href="https://ieeexplore.ieee.org/abstract/document/9551285">[PDF]</a>
  <a href="https://github.com/YuZhang-SMU/Breast-Lesion-Segmentation">[Code]</a>
</p>
<p style="width:1400px" class="auto_align">
  <img src="pic/Fig2.png" align="left" width="500" hspace="5" vspace="5">
  <p style="width:1400px" class="divcss5 auto_align">
  <b>
  <span>
  [Abstract]
  </span>
  </b>
  Deep learning methods, especially convolutional neural networks, have been successfully applied to lesion segmentation in breast ultrasound (BUS) images. However, pattern complexity and intensity similarity between the surrounding tissues (i.e., background) and lesion regions (i.e., foreground) bring challenges for lesion segmentation. Considering that such rich texture information is contained in background, very few methods have tried to explore and exploit background-salient representations for assisting foreground segmentation. Additionally, other characteristics of BUS images, i.e., 1) low-contrast appearance and blurry boundary, and 2) significant shape and position variation of lesions, also increase the difficulty in accurate lesion segmentation. In this paper, we present a saliency-guided morphology-aware U-Net (SMU-Net) for lesion segmentation in BUS images. The SMU-Net is composed of a main network with an additional middle stream and an auxiliary network. Specifically, we first propose generation of saliency maps which incorporate both low-level and high-level image structures, for foreground and background. These saliency maps are then employed to guide the main network and auxiliary network for respectively learning foreground-salient and background-salient representations. Furthermore, we devise an additional middle stream which basically consists of background-assisted fusion, shape-aware, edge-aware and position-aware units. This stream receives the coarse-to-fine representations from the main network and auxiliary network for efficiently fusing the foreground-salient and background-salient features and enhancing the ability of learning morphological information for network. Extensive experiments on five datasets demonstrate higher performance and superior robustness to the scale of dataset than several state-of-the-art deep learning approaches in breast lesion segmentation in ultrasound image.
  </p>
</p>
</ul>

<h3>2019</h3>

<ul>
<p style="width:1400px" class="auto_align">
  <span>1</span>. Zhenyuan Ning, Shengzhou Zhong, Qianjin Feng, Wufan Chen, and <b>Yu Zhang</b>.
  SMU-Net: Saliency-guided Morphology-aware U-Net for Breast Lesion Segmentation in Ultrasound Image. 
  <i style="color:#3333CC">IEEE Transactions on Medical Imaging (TMI).</i>
  <a href="https://ieeexplore.ieee.org/abstract/document/9551285">[PDF]</a>
  <a href="https://github.com/YuZhang-SMU/Breast-Lesion-Segmentation">[Code]</a>
</p>
<p style="width:1400px" class="auto_align">
  <img src="pic/Fig2.png" align="left" width="500" hspace="5" vspace="5">
  <p style="width:1400px" class="divcss5 auto_align">
  <b>
  <span>
  [Abstract]
  </span>
  </b>
  Deep learning methods, especially convolutional neural networks, have been successfully applied to lesion segmentation in breast ultrasound (BUS) images. However, pattern complexity and intensity similarity between the surrounding tissues (i.e., background) and lesion regions (i.e., foreground) bring challenges for lesion segmentation. Considering that such rich texture information is contained in background, very few methods have tried to explore and exploit background-salient representations for assisting foreground segmentation. Additionally, other characteristics of BUS images, i.e., 1) low-contrast appearance and blurry boundary, and 2) significant shape and position variation of lesions, also increase the difficulty in accurate lesion segmentation. In this paper, we present a saliency-guided morphology-aware U-Net (SMU-Net) for lesion segmentation in BUS images. The SMU-Net is composed of a main network with an additional middle stream and an auxiliary network. Specifically, we first propose generation of saliency maps which incorporate both low-level and high-level image structures, for foreground and background. These saliency maps are then employed to guide the main network and auxiliary network for respectively learning foreground-salient and background-salient representations. Furthermore, we devise an additional middle stream which basically consists of background-assisted fusion, shape-aware, edge-aware and position-aware units. This stream receives the coarse-to-fine representations from the main network and auxiliary network for efficiently fusing the foreground-salient and background-salient features and enhancing the ability of learning morphological information for network. Extensive experiments on five datasets demonstrate higher performance and superior robustness to the scale of dataset than several state-of-the-art deep learning approaches in breast lesion segmentation in ultrasound image.
  </p>
</p>
</ul>


<h3>2018</h3>

<ul>
<p style="width:1400px" class="auto_align">
  <span>1</span>. Zhenyuan Ning, Shengzhou Zhong, Qianjin Feng, Wufan Chen, and <b>Yu Zhang</b>.
  SMU-Net: Saliency-guided Morphology-aware U-Net for Breast Lesion Segmentation in Ultrasound Image. 
  <i style="color:#3333CC">IEEE Transactions on Medical Imaging (TMI).</i>
  <a href="https://ieeexplore.ieee.org/abstract/document/9551285">[PDF]</a>
  <a href="https://github.com/YuZhang-SMU/Breast-Lesion-Segmentation">[Code]</a>
</p>
<p style="width:1400px" class="auto_align">
  <img src="pic/Fig2.png" align="left" width="500" hspace="5" vspace="5">
  <p style="width:1400px" class="divcss5 auto_align">
  <b>
  <span>
  [Abstract]
  </span>
  </b>
  Deep learning methods, especially convolutional neural networks, have been successfully applied to lesion segmentation in breast ultrasound (BUS) images. However, pattern complexity and intensity similarity between the surrounding tissues (i.e., background) and lesion regions (i.e., foreground) bring challenges for lesion segmentation. Considering that such rich texture information is contained in background, very few methods have tried to explore and exploit background-salient representations for assisting foreground segmentation. Additionally, other characteristics of BUS images, i.e., 1) low-contrast appearance and blurry boundary, and 2) significant shape and position variation of lesions, also increase the difficulty in accurate lesion segmentation. In this paper, we present a saliency-guided morphology-aware U-Net (SMU-Net) for lesion segmentation in BUS images. The SMU-Net is composed of a main network with an additional middle stream and an auxiliary network. Specifically, we first propose generation of saliency maps which incorporate both low-level and high-level image structures, for foreground and background. These saliency maps are then employed to guide the main network and auxiliary network for respectively learning foreground-salient and background-salient representations. Furthermore, we devise an additional middle stream which basically consists of background-assisted fusion, shape-aware, edge-aware and position-aware units. This stream receives the coarse-to-fine representations from the main network and auxiliary network for efficiently fusing the foreground-salient and background-salient features and enhancing the ability of learning morphological information for network. Extensive experiments on five datasets demonstrate higher performance and superior robustness to the scale of dataset than several state-of-the-art deep learning approaches in breast lesion segmentation in ultrasound image.
  </p>
</p>
</ul>

<ul>
<p style="width:1400px" class="auto_align">
  <span>2</span>. Zhenyuan Ning, Shengzhou Zhong, Qianjin Feng, Wufan Chen, and <b>Yu Zhang</b>.
  SMU-Net: Saliency-guided Morphology-aware U-Net for Breast Lesion Segmentation in Ultrasound Image. 
  <i style="color:#3333CC">IEEE Transactions on Medical Imaging (TMI).</i>
  <a href="https://ieeexplore.ieee.org/abstract/document/9551285">[PDF]</a>
  <a href="https://github.com/YuZhang-SMU/Breast-Lesion-Segmentation">[Code]</a>
</p>
<p style="width:1400px" class="auto_align">
  <img src="pic/Fig2.png" align="left" width="500" hspace="5" vspace="5">
  <p style="width:1400px" class="divcss5 auto_align">
  <b>
  <span>
  [Abstract]
  </span>
  </b>
  Deep learning methods, especially convolutional neural networks, have been successfully applied to lesion segmentation in breast ultrasound (BUS) images. However, pattern complexity and intensity similarity between the surrounding tissues (i.e., background) and lesion regions (i.e., foreground) bring challenges for lesion segmentation. Considering that such rich texture information is contained in background, very few methods have tried to explore and exploit background-salient representations for assisting foreground segmentation. Additionally, other characteristics of BUS images, i.e., 1) low-contrast appearance and blurry boundary, and 2) significant shape and position variation of lesions, also increase the difficulty in accurate lesion segmentation. In this paper, we present a saliency-guided morphology-aware U-Net (SMU-Net) for lesion segmentation in BUS images. The SMU-Net is composed of a main network with an additional middle stream and an auxiliary network. Specifically, we first propose generation of saliency maps which incorporate both low-level and high-level image structures, for foreground and background. These saliency maps are then employed to guide the main network and auxiliary network for respectively learning foreground-salient and background-salient representations. Furthermore, we devise an additional middle stream which basically consists of background-assisted fusion, shape-aware, edge-aware and position-aware units. This stream receives the coarse-to-fine representations from the main network and auxiliary network for efficiently fusing the foreground-salient and background-salient features and enhancing the ability of learning morphological information for network. Extensive experiments on five datasets demonstrate higher performance and superior robustness to the scale of dataset than several state-of-the-art deep learning approaches in breast lesion segmentation in ultrasound image.
  </p>
</p>
</ul>

<ul>
<p style="width:1400px" class="auto_align">
  <span>3</span>. Zhenyuan Ning, Shengzhou Zhong, Qianjin Feng, Wufan Chen, and <b>Yu Zhang</b>.
  SMU-Net: Saliency-guided Morphology-aware U-Net for Breast Lesion Segmentation in Ultrasound Image. 
  <i style="color:#3333CC">IEEE Transactions on Medical Imaging (TMI).</i>
  <a href="https://ieeexplore.ieee.org/abstract/document/9551285">[PDF]</a>
  <a href="https://github.com/YuZhang-SMU/Breast-Lesion-Segmentation">[Code]</a>
</p>
<p style="width:1400px" class="auto_align">
  <img src="pic/Fig2.png" align="left" width="500" hspace="5" vspace="5">
  <p style="width:1400px" class="divcss5 auto_align">
  <b>
  <span>
  [Abstract]
  </span>
  </b>
  Deep learning methods, especially convolutional neural networks, have been successfully applied to lesion segmentation in breast ultrasound (BUS) images. However, pattern complexity and intensity similarity between the surrounding tissues (i.e., background) and lesion regions (i.e., foreground) bring challenges for lesion segmentation. Considering that such rich texture information is contained in background, very few methods have tried to explore and exploit background-salient representations for assisting foreground segmentation. Additionally, other characteristics of BUS images, i.e., 1) low-contrast appearance and blurry boundary, and 2) significant shape and position variation of lesions, also increase the difficulty in accurate lesion segmentation. In this paper, we present a saliency-guided morphology-aware U-Net (SMU-Net) for lesion segmentation in BUS images. The SMU-Net is composed of a main network with an additional middle stream and an auxiliary network. Specifically, we first propose generation of saliency maps which incorporate both low-level and high-level image structures, for foreground and background. These saliency maps are then employed to guide the main network and auxiliary network for respectively learning foreground-salient and background-salient representations. Furthermore, we devise an additional middle stream which basically consists of background-assisted fusion, shape-aware, edge-aware and position-aware units. This stream receives the coarse-to-fine representations from the main network and auxiliary network for efficiently fusing the foreground-salient and background-salient features and enhancing the ability of learning morphological information for network. Extensive experiments on five datasets demonstrate higher performance and superior robustness to the scale of dataset than several state-of-the-art deep learning approaches in breast lesion segmentation in ultrasound image.
  </p>
</p>
</ul>

</td>
</tr>
</table>
</body>
</html>
