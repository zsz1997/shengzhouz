<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Shengzhou Zhong</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">MENU</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="publications.html">Publications</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Shengzhou Zhong</h1>
</div>
<table class="imgtable"><tr><td>
<a href="https://zsz1997.github.io/"><img src="pic/cv_photo.png" alt="alt text" width="160px" height="120px" /></a>&nbsp;</td>
<td align="left"><p>postgraduate candidate @ School of Biomedical Engineering, Southern Medical University (SMU)<br />
1838 Guangzhou Avenue North, Baiyun District, Guangzhou City, Guangdong Province, China <br /></p>
<p>E-mail: <a href="mailto:zsz2016@i.smu.edu.cn">zsz2016@i.smu.edu.cn</a></p>
</td></tr></table>

<p style="width:1000px">
<img src="pic/Fig2.png" align="left" width="300" hspace="10" vspace="10">
Deep learning methods, especially convolutional neural networks, have been successfully applied to lesion segmentation in breast ultrasound (BUS) images. However, pattern complexity and intensity similarity between the surrounding tissues (i.e., background) and lesion regions (i.e., foreground) bring challenges for lesion segmentation. Considering that such rich texture information is contained in background, very few methods have tried to explore and exploit background-salient representations for assisting foreground segmentation. Additionally, other characteristics of BUS images, i.e., 1) low-contrast appearance and blurry boundary, and 2) significant shape and position variation of lesions, also increase the difficulty in accurate lesion segmentation. In this paper, we present a saliency-guided morphology-aware U-Net (SMU-Net) for lesion segmentation in BUS images. The SMU-Net is composed of a main network with an additional middle stream and an auxiliary network. Specifically, we first propose generation of saliency maps which incorporate both low-level and high-level image structures, for foreground and background. These saliency maps are then employed to guide the main network and auxiliary network for respectively learning foreground-salient and background-salient representations. Furthermore, we devise an additional middle stream which basically consists of background-assisted fusion, shape-aware, edge-aware and position-aware units. This stream receives the coarse-to-fine representations from the main network and auxiliary network for efficiently fusing the foreground-salient and background-salient features and enhancing the ability of learning morphological information for network. Extensive experiments on five datasets demonstrate higher performance and superior robustness to the scale of dataset than several state-of-the-art deep learning approaches in breast lesion segmentation in ultrasound image.
</p>

<h2>Biography</h2>
<p>I am currently a 2rd-year postgraduate Student at the School of Biomedical Engineering, Southern Medical University (SMU), China, 
under the supervision of Prof. <a href="https://portal.smu.edu.cn/swyxgcxy/info/1020/1241.htm">Yu Zhang</a>. </p>
<p>My research interests mainly focus on deep learning technologies for medical image analysis, 
especially annotation-limited 3D medical image segmentation. </p>
<h4>I am looking for a post-doc position or a medical-AI related job!</h4>
<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=400&t=tt&d=l9igJTrQusUKk6mPyZa9b0_ebEFoc05DAT5OyMG1eow&co=ffffff&cmo=3acc3a&cmn=ff5353&ct=808080'></script>
</td>
</tr>
</table>
</body>
</html>
